{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:06.879402Z",
     "start_time": "2024-12-17T11:08:06.877664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATASET = \"swedish_tunes_int.csv\"\n",
    "TRANSLATION_FILE = \"translation\"\n",
    "INPUT_SIZE = 5\n",
    "HIDDEN_NODES = 256\n",
    "NUM_LAYERS = 1\n",
    "SEED = 0\n",
    "LEARNING_RATE = 0.1"
   ],
   "id": "5a86137d439a39c5",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:06.925024Z",
     "start_time": "2024-12-17T11:08:06.922521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translation_p = open(TRANSLATION_FILE, 'r')\n",
    "translation_lines = translation_p.readlines()\n",
    "num_tokens = len(translation_lines)\n",
    "\n",
    "translation_p.close()\n",
    "num_tokens"
   ],
   "id": "9e0ce4d828bf1598",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:06.971081Z",
     "start_time": "2024-12-17T11:08:06.969452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas\n",
    "from torch.nn import RNN, Linear, Softmax, Module\n",
    "import torch\n",
    "import math"
   ],
   "id": "74e516b3cc31beb",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:07.017262Z",
     "start_time": "2024-12-17T11:08:07.015200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Class that creates the model that we'll use\n",
    "class PredictRNN(Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PredictRNN, self).__init__()\n",
    "\n",
    "        self.rnn = RNN(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.h2o = Linear(hidden_size, output_size)\n",
    "        self.softmax = Softmax(dim=0)\n",
    "\n",
    "    def forward(self, line_tensor):\n",
    "        rnn_out, hidden = self.rnn(line_tensor)\n",
    "        output = self.h2o(hidden[0])\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ],
   "id": "bd30915ed2048d7f",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:07.082685Z",
     "start_time": "2024-12-17T11:08:07.062407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get min number of tokens in a line\n",
    "def trim_small_lines(filepath, input_size):\n",
    "    file_p = open(filepath, 'r')\n",
    "    lines = list(file_p.readlines())\n",
    "    for line in lines:\n",
    "        line_tok = line.split(',')\n",
    "        line_len = len(line_tok)\n",
    "        if line_len < input_size:\n",
    "            lines.remove(line)\n",
    "    file_p.close()\n",
    "    return lines\n",
    "\n",
    "trim_small_lines(DATASET, INPUT_SIZE)[:5]"
   ],
   "id": "24149e2b1065b9f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,1,2,3,4,5,3,6,3,5,3,7,5,5,5,8,5,3,5,4,7,3,4,5,3,6,3,5,3,7,5,5,5,8,9,10,11,12,13,14,13,7,5,5,5,15,15,3,16,3,7,12,13,14,13,7,5,5,5,8,9,17\\n',\n",
       " '0,1,2,18,19,20,21,22,6,7,23,3,15,23,12,7,6,6,22,24,25,3,12,26,7,27,22,22,21,18,7,13,23,15,27,28,7,29,19,22,23,12,30,31,32,12,12,7,6,20,29,19,33,29,19,20,7,18,19,20,21,22,6,7,23,3,15,23,12,17\\n',\n",
       " '0,1,2,22,6,23,15,13,18,7,33,29,19,22,34,7,6,6,22,3,15,3,16,13,35,7,24,12,6,23,6,20,7,22,6,23,15,13,18,7,33,29,19,22,34,30,19,36,37,15,6,19,33,7,38,39,39,29,33,7,40,33,29,19,26,38,7,12,20,29,41,17\\n',\n",
       " '0,1,2,24,4,25,13,3,25,7,3,5,8,23,9,7,6,6,29,4,8,25,5,3,3,3,3,7,8,25,5,15,3,6,6,6,7,8,25,5,3,25,3,3,3,7,3,5,8,23,9,30,12,12,31,32,7,12,42,43,7,24,4,25,13,3,25,7,3,5,8,23,9,17\\n',\n",
       " '0,1,2,44,45,23,15,7,46,47,48,47,12,7,6,20,49,50,51,46,52,46,50,46,7,6,25,15,3,7,46,47,48,5,8,7,47,52,50,53,24,30,54,45,3,20,7,3,20,19,20,7,44,45,23,15,7,46,47,48,47,12,17\\n']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:07.128212Z",
     "start_time": "2024-12-17T11:08:07.126055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculates the accuracy of the predictions of a neural network\n",
    "# For classification tasks\n",
    "# NOTE: X and y should already be PyTorch tensors\n",
    "def calculate_accuracy(network, X, y):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "    # make predictions for the given X\n",
    "    probs = network(X)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    # the calculate accuracy of those predictions\n",
    "    total = len(predictions)\n",
    "    accuracy = sum(predictions == y) / total\n",
    "    variance = accuracy * (1 - accuracy)\n",
    "    std_err = math.sqrt(variance / total)\n",
    "    up_bound = accuracy + 2.39 * std_err\n",
    "    low_bound = accuracy - 2.39 * std_err\n",
    "    return float(accuracy), up_bound, low_bound\n"
   ],
   "id": "b5670583c9f2e8e",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:07.176880Z",
     "start_time": "2024-12-17T11:08:07.175031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# converts a training set into smaller train and validation sets\n",
    "def create_validation(training_X, training_y, valid_percentage):\n",
    "    # find the split point between training and validation\n",
    "    training_n = training_X.shape[0]\n",
    "    valid_rows = int(valid_percentage * training_n)\n",
    "\n",
    "    # create the validation set\n",
    "    valid_X = training_X.iloc[:valid_rows]\n",
    "    valid_y = training_y.iloc[:valid_rows]\n",
    "\n",
    "    # create the (smaller) training set\n",
    "    train_X = training_X.iloc[valid_rows:]\n",
    "    train_y = training_y.iloc[valid_rows:]\n",
    "\n",
    "    return train_X, train_y, valid_X, valid_y\n"
   ],
   "id": "96dab109b9180c6d",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:07.227557Z",
     "start_time": "2024-12-17T11:08:07.224264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trains a neural network with given training data\n",
    "def train_network(network, training_X, training_y, lr, nn_filepath):\n",
    "    # split the training data into train and validation\n",
    "    # Note: use 20% of the original training data for validation\n",
    "    train_X, train_y, valid_X, valid_y = create_validation(training_X, training_y, 0.2)\n",
    "\n",
    "    # convert our data to PyTorch objects\n",
    "    train_X = torch.from_numpy(train_X.values).float()\n",
    "    train_y = torch.from_numpy(train_y.values).long()\n",
    "    valid_X = torch.from_numpy(valid_X.values).float()\n",
    "    valid_y = torch.from_numpy(valid_y.values).long()\n",
    "\n",
    "    # move the data and model to the GPU if possible\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "        print(f\"Using device {torch.cuda.get_device_name(device)}\")\n",
    "        train_X = train_X.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        valid_X = valid_X.to(device)\n",
    "        valid_y = valid_y.to(device)\n",
    "        network = network.to(device)\n",
    "\n",
    "    # create the algorithm that learns the weight for the network\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    # create the loss function that tells optimizer how much error it has in its predictions\n",
    "    # here we use cross entropy since we have a classification task with more than two possible labels\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # train for 1000 epochs\n",
    "    num_epochs = 1000\n",
    "    train_loss_values = []\n",
    "    valid_loss_values = []\n",
    "    train_acc_values = []\n",
    "    valid_acc_values = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # network.zero_grad()\n",
    "        # # make predictions on the training set and validation set\n",
    "        # for X_vec, y_label in zip(train_X, train_y):\n",
    "        #     prediction = network(X_vec)\n",
    "        #     loss = loss_function(prediction, y_label)\n",
    "        train_predictions = network(train_X)\n",
    "        valid_predictions = network(valid_X)\n",
    "        train_loss = loss_function(train_predictions, train_y)\n",
    "\n",
    "        # calculate the error on the training set\n",
    "        train_loss_values.append(train_loss.item())\n",
    "        valid_loss_values.append(loss_function(valid_predictions, valid_y).item())\n",
    "        train_acc_values.append(calculate_accuracy(network, train_X, train_y))\n",
    "        valid_acc = calculate_accuracy(network, valid_X, valid_y)\n",
    "        valid_acc_values.append(valid_acc)\n",
    "\n",
    "        # Early return for perfect fit\n",
    "        if valid_acc == 1:\n",
    "            # convert the training progress data to a Pandas DataFrame\n",
    "            progress = {\n",
    "                \"epoch\": range(epoch+1),\n",
    "                \"train_loss\": train_loss_values,\n",
    "                \"valid_loss\": valid_loss_values,\n",
    "                \"train_acc\": train_acc_values,\n",
    "                \"valid_acc\": valid_acc_values\n",
    "            }\n",
    "            torch.save(network, nn_filepath)\n",
    "            return pandas.DataFrame(progress)\n",
    "\n",
    "        # perform backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # convert the training progress data to a Pandas DataFrame\n",
    "    progress = {\n",
    "        \"epoch\": range(num_epochs),\n",
    "        \"train_loss\": train_loss_values,\n",
    "        \"valid_loss\": valid_loss_values,\n",
    "        \"train_acc\": train_acc_values,\n",
    "        \"valid_acc\": valid_acc_values\n",
    "    }\n",
    "    torch.save(network, nn_filepath)\n",
    "    return pandas.DataFrame(progress)\n"
   ],
   "id": "5481cd12534aab3f",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:08.270882Z",
     "start_time": "2024-12-17T11:08:07.267059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataset(dataset_filepath, input_size):\n",
    "    lines = trim_small_lines(dataset_filepath, input_size)\n",
    "    # We need to create a dataframe with the proper number of columns\n",
    "    # Get the first three tokens from every line and store them in front of each instance\n",
    "    dataframe_dict = {\n",
    "        'timesig': [],\n",
    "        'key': [],\n",
    "        'style': []\n",
    "    }\n",
    "\n",
    "    for i in range(input_size):\n",
    "        dataframe_dict[i] = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(',')\n",
    "        timesig = int(line[0])\n",
    "        key = int(line[1])\n",
    "        style = int(line[2])\n",
    "        remainder = list(map(int, line[3:]))\n",
    "        for i in range(len(remainder) - input_size):\n",
    "            window = remainder[i:i+input_size]\n",
    "            dataframe_dict['timesig'].append(timesig)\n",
    "            dataframe_dict['key'].append(key)\n",
    "            dataframe_dict['style'].append(style)\n",
    "            for ind, token in enumerate(window):\n",
    "                dataframe_dict[ind].append(token)\n",
    "\n",
    "    return pandas.DataFrame(dataframe_dict)\n",
    "\n",
    "process_dataset(DATASET, INPUT_SIZE)"
   ],
   "id": "bd1e108aa75d8881",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        timesig  key  style   0   1   2   3    4\n",
       "0             0    1      2   3   4   5   3    6\n",
       "1             0    1      2   4   5   3   6    3\n",
       "2             0    1      2   5   3   6   3    5\n",
       "3             0    1      2   3   6   3   5    3\n",
       "4             0    1      2   6   3   5   3    7\n",
       "...         ...  ...    ...  ..  ..  ..  ..  ...\n",
       "901002        0    1    800  35  14   7  43   27\n",
       "901003        0    1    800  14   7  43  27   27\n",
       "901004        0    1    800   7  43  27  27    7\n",
       "901005        0    1    800  43  27  27   7   76\n",
       "901006        0    1    800  27  27   7  76  121\n",
       "\n",
       "[901007 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timesig</th>\n",
       "      <th>key</th>\n",
       "      <th>style</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901002</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901003</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901004</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901005</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901006</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>901007 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:09.320420Z",
     "start_time": "2024-12-17T11:08:08.288519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splits a dataset into training and test sets,\n",
    "def split_dataset(dataset, train_data_ratio, y_label, seed=SEED):\n",
    "    training = dataset.sample(frac=train_data_ratio, random_state=seed)\n",
    "    test = dataset.drop(training.index)\n",
    "    training_y = training[y_label]\n",
    "    training_X = training.drop(columns=y_label)\n",
    "    test_y = test[y_label]\n",
    "    test_X = test.drop(columns=y_label)\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "dataset = process_dataset(DATASET, INPUT_SIZE)\n",
    "training_X, training_y, test_X, test_y = split_dataset(dataset, 0.9, 4, 0)\n",
    "training_X\n"
   ],
   "id": "96eef429c91e6259",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        timesig  key  style    0    1    2   3\n",
       "119510        0    1    575   42   13    7  14\n",
       "31816        64    1    274  121   79   11  20\n",
       "898913        0  179    800    6    7  193   7\n",
       "295356      128  179    172   25    7  163  55\n",
       "531065      128    1    172   55  212   55   7\n",
       "...         ...  ...    ...  ...  ...  ...  ..\n",
       "215929      128  179    720   16   57   16   5\n",
       "712481      128    1    725    7   88   22  12\n",
       "351176      128  179    172    5  187  188   7\n",
       "589603      128  179    172  187   15   23  15\n",
       "828331      128    1   1121   22   26    7  13\n",
       "\n",
       "[810906 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timesig</th>\n",
       "      <th>key</th>\n",
       "      <th>style</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119510</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31816</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>121</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898913</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>800</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>193</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295356</th>\n",
       "      <td>128</td>\n",
       "      <td>179</td>\n",
       "      <td>172</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531065</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>55</td>\n",
       "      <td>212</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215929</th>\n",
       "      <td>128</td>\n",
       "      <td>179</td>\n",
       "      <td>720</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712481</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "      <td>7</td>\n",
       "      <td>88</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351176</th>\n",
       "      <td>128</td>\n",
       "      <td>179</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589603</th>\n",
       "      <td>128</td>\n",
       "      <td>179</td>\n",
       "      <td>172</td>\n",
       "      <td>187</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828331</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810906 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:09.347769Z",
     "start_time": "2024-12-17T11:08:09.346110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Performs one-hot encoding on dataset AFTER process_dataset\n",
    "# Napkin estimates this would take 27 hours to run on swedish dataset\n",
    "def onehots(dataframe, n_tokens):\n",
    "    ret_frame = pandas.DataFrame()\n",
    "    for column_name, column in dataframe.items():\n",
    "        oh_dict = {}\n",
    "        for ix in range(n_tokens):\n",
    "            oh_dict[str(column_name) + '_' + str(ix)] = []\n",
    "        for item in column:\n",
    "            print(item)\n",
    "            for key, array in oh_dict.items():\n",
    "                if item == int(key.split('_')[1]):\n",
    "                    array.append(1)\n",
    "                else:\n",
    "                    array.append(0)\n",
    "        ret_frame = pandas.concat([ret_frame, pandas.DataFrame(oh_dict)], axis=1)\n",
    "    return ret_frame"
   ],
   "id": "4ab2da7d8a027e1a",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:08:36.809549Z",
     "start_time": "2024-12-17T11:08:11.098723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rnn = PredictRNN(INPUT_SIZE+2, HIDDEN_NODES, NUM_LAYERS, num_tokens)\n",
    "results = train_network(rnn, training_X, training_y, LEARNING_RATE, 'trained_rnn.pt')\n",
    "test_X = torch.from_numpy(test_X.values).float()\n",
    "test_y = torch.from_numpy(test_y.values).long()\n",
    "accuracy, up_bound, low_bound = calculate_accuracy(rnn, test_X, test_y)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"95% Confidence Interval: [{low_bound:.3f}, {up_bound:.3f}]\")\n"
   ],
   "id": "abc8ee6fdb12ed27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device AMD Radeon RX 7900 XT\n",
      "training_X\n",
      "torch.Size([648725, 7])\n",
      "train_predictions\n",
      "torch.Size([1178])\n",
      "train_y\n",
      "torch.Size([648725])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [1178], target: [648725])",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[96], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m rnn \u001B[38;5;241m=\u001B[39m PredictRNN(INPUT_SIZE\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m2\u001B[39m, HIDDEN_NODES, NUM_LAYERS, num_tokens)\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLEARNING_RATE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrained_rnn.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m test_X \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(test_X\u001B[38;5;241m.\u001B[39mvalues)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m      4\u001B[0m test_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(test_y\u001B[38;5;241m.\u001B[39mvalues)\u001B[38;5;241m.\u001B[39mlong()\n",
      "Cell \u001B[0;32mIn[92], line 46\u001B[0m, in \u001B[0;36mtrain_network\u001B[0;34m(network, training_X, training_y, lr, nn_filepath)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_y\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_y\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m---> 46\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# calculate the error on the training set\u001B[39;00m\n\u001B[1;32m     49\u001B[0m train_loss_values\u001B[38;5;241m.\u001B[39mappend(train_loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/Documents/CSCI373/Songwriter-s-Block/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CSCI373/Songwriter-s-Block/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/CSCI373/Songwriter-s-Block/venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1293\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1294\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CSCI373/Songwriter-s-Block/venv/lib/python3.12/site-packages/torch/nn/functional.py:3479\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3478\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3479\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3480\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3481\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3482\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3483\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3486\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: size mismatch (got input: [1178], target: [648725])"
     ]
    }
   ],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
